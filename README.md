A Variational Bayesian Approach for Multimodal Multi-instance Classification

Abstract In multiple instance learning (MIL), objects are represented by bags of instances. Each instance shares the same feature set but has unique feature values. MIL aims to train models that predict bag-level outcomes based on features of these instances, making it a weakly supervised approach due to the lack of instance-level labels. While MIL methods focusing on binary classification are abundant, they often cannot identify which specific instances drive bag labels and have limited or little interpretability. Xiong et al. (2024) introduced MICProB, a Bayesian multiple instance classification (MIC) method that addresses these issues. However, MICProB is computationally intensive and best suited for unimodal instances. To overcome these limitations, we propose vMMIC, a novel variational Bayesian approach for multimodal MIC. vMMIC handles diverse instance types and significantly improves computational efficiency by leveraging Bayesian variational inference, coupled with the data augmentation technique. We benchmark vMMIC against MICProB and many other commonly used MIC approaches on both simulated and real-world data. Results demonstrate vMMIC's superior performance, faster computation, and improved interpretability.
